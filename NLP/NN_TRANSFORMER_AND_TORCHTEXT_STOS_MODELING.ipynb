{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NN.TRANSFORMER AND TORCHTEXT : STOS(sequence to sequence) MODELING."
      ],
      "metadata": {
        "id": "vbEk3eV2bXyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "  def __init__(self, ntoken: int, d_model: int, nhead:int, d_hid:int, nlayers:int, dropout:float =0.5):\n",
        "    super().__init__()\n",
        "    self.model_type = 'Transformer'\n",
        "    self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "    encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "    self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "    self.encoder = nn.Embedding(ntoken, d_model)\n",
        "    self.d_model = d_model\n",
        "    self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self) -> None:\n",
        "    initrange = 0.1\n",
        "    self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "    self.decoder.bias.data.zero_()\n",
        "    self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "  def forward(self, src:Tensor, src_mask:Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      src : Tensor, shape ''[seq_len, batch_size]''\n",
        "      src_mask : Tensor, shape ''[seq_len, seq_len]''\n",
        "\n",
        "    Returns:\n",
        "      output Tensor of shape ''[seq_len, batch_size, ntoken]''\n",
        "    \"\"\"\n",
        "\n",
        "    src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "    src = self.pos_encoder(src)\n",
        "    output = self.transformer_encoder(src, src_mask)\n",
        "    output = self.decoder(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz : int) -> Tensor:\n",
        "  \"\"\"Generates an upper - triangular matrix of ''-inf'', with zeros on ''diag''.\"\"\"\n",
        "  return torch.triu(torch.ones(sz,sz) * float('-inf'), diagonal = 1)\n"
      ],
      "metadata": {
        "id": "tmh-wqQAbXXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding module : sequence inner token 상대적, 절대적 position에 대한 info 주입, positional encoding + embedding 합칠 수 있도록 차원을 가짐. another frequency : sine function and cosine function using"
      ],
      "metadata": {
        "id": "mYmWLeHlfmqI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKf3-kKbbPKK"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "  def __init__(self, d_model:int, dropout:float=0.1, max_len : int = 5000):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    position = torch.arange(max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0)/d_model))\n",
        "    pe = torch.zeros(max_len, 1, d_model)\n",
        "    pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "    self.register_buffer('pe',pe)\n",
        "\n",
        "  def forward(self, x:Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      x : Tensor, shape ''[seq_len, batch_size, embedding_dim]''\n",
        "    \"\"\"\n",
        "    x = x + self.pe[:x.size(0)]\n",
        "    return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akAz9fSdhLnn",
        "outputId": "03ee88ab-daa4-4929-8ad7-012e8244585e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata) (16.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchdata) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchdata) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwt8nayvlZs0",
        "outputId": "d43ea77e-fb53-4d32-a141-e66e8b776f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import portalocker\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Arguments:\n",
        "        data: Tensor, shape ``[N]``\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape ``[N // bsz, bsz]``\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ],
      "metadata": {
        "id": "ASH_l64ihfoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create input and target sequence function\n",
        "<hr>\n",
        "get_batch() function : create input-target seqeunce pair for transformer model. function source data : bptt lenght -> 덩어리로 세분화, language modeling report위해 model은 next word target 필요"
      ],
      "metadata": {
        "id": "ZsL2vIvioKb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bptt = 35\n",
        "\n",
        "def get_batch(source: Tensor, i :int) -> Tuple[Tensor, Tensor]:\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    source : Tensor, shape ''[full_seq_len, batch_size]''\n",
        "    i:int\n",
        "\n",
        "  Returns:\n",
        "    tuple ''(data, target)'', where data has shape ''[seq_len, batch_size]'' and\n",
        "    target has shape ''[seq_len * batch_size]''\n",
        "  \"\"\"\n",
        "\n",
        "  seq_len =  min(bptt, len(source) -1 -i)\n",
        "  data = source[i:i+seq_len]\n",
        "  target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "  return data, target"
      ],
      "metadata": {
        "id": "7SZfYoklnVWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# instance reset\n",
        "<hr>\n",
        "model hyperparameter define"
      ],
      "metadata": {
        "id": "NUkU5XQ1oyjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(vocab) # word vocab size\n",
        "emsize = 200 # embadding dimenssion\n",
        "d_hid = 200 # ''nn.TransformerEncode'' feedforward network model demenssion\n",
        "nlayers = 2 # ''nn.TransformerEncoder'' inner nn.TransformerEncoderLayer count\n",
        "nhead = 2 # ''nn.MultiheadAttention'' head count\n",
        "dropout = 0.2 # dropout percent\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ],
      "metadata": {
        "id": "WMjn0lI8oH5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "<hr>\n",
        "CrossEntropyLoss : SGD(확률적 경사 하강법) optimizer , learning rate : 0.5 set , StepLR schedule , use the nn.utils.clip_grad_norm_ and gradient dosen't exploding"
      ],
      "metadata": {
        "id": "cqT6qJ78qrUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # 학습률(learning rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # 학습 모드 시작\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        seq_len = data.size(0)\n",
        "        if seq_len != bptt:  # 마지막 배치에만 적용\n",
        "            src_mask = src_mask[:seq_len, :seq_len]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # 평가 모드 시작\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            seq_len = data.size(0)\n",
        "            if seq_len != bptt:\n",
        "                src_mask = src_mask[:seq_len, :seq_len]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ],
      "metadata": {
        "id": "H4ht3ed2p14r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch 내에서 loop if validation loss 가 관찰중 최적이라면 model에 save"
      ],
      "metadata": {
        "id": "kEsOHRczuOpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 3\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        train(model)\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQkQofGQuMqc",
        "outputId": "f7b23601-c915-4ce9-c987-aa90754a40b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 14.03 | loss  6.76 | ppl   858.85\n",
            "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 13.24 | loss  6.54 | ppl   693.83\n",
            "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 13.28 | loss  6.28 | ppl   531.22\n",
            "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 13.33 | loss  6.21 | ppl   498.16\n",
            "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 13.65 | loss  6.12 | ppl   454.72\n",
            "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 13.45 | loss  6.10 | ppl   447.25\n",
            "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 13.32 | loss  6.07 | ppl   432.51\n",
            "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 13.34 | loss  6.08 | ppl   437.29\n",
            "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 13.47 | loss  6.00 | ppl   404.60\n",
            "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 13.81 | loss  5.99 | ppl   401.36\n",
            "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 13.46 | loss  5.87 | ppl   355.33\n",
            "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 13.44 | loss  5.95 | ppl   382.90\n",
            "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 13.52 | loss  5.93 | ppl   375.18\n",
            "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 13.86 | loss  5.86 | ppl   349.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 41.56s | valid loss  5.77 | valid ppl   321.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 13.58 | loss  5.78 | ppl   324.65\n",
            "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 13.54 | loss  5.81 | ppl   332.67\n",
            "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 13.87 | loss  5.64 | ppl   281.53\n",
            "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 13.69 | loss  5.69 | ppl   294.44\n",
            "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 13.53 | loss  5.64 | ppl   281.44\n",
            "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 13.56 | loss  5.68 | ppl   291.91\n",
            "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 13.60 | loss  5.68 | ppl   293.29\n",
            "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 13.99 | loss  5.71 | ppl   302.45\n",
            "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 13.58 | loss  5.65 | ppl   283.40\n",
            "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 13.56 | loss  5.67 | ppl   291.18\n",
            "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 13.63 | loss  5.54 | ppl   255.90\n",
            "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 14.02 | loss  5.65 | ppl   283.22\n",
            "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 13.75 | loss  5.65 | ppl   283.06\n",
            "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 13.62 | loss  5.58 | ppl   264.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 42.01s | valid loss  5.63 | valid ppl   278.64\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 14.14 | loss  5.55 | ppl   257.37\n",
            "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 13.76 | loss  5.59 | ppl   268.08\n",
            "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 13.72 | loss  5.41 | ppl   222.92\n",
            "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 13.68 | loss  5.47 | ppl   236.68\n",
            "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 13.89 | loss  5.43 | ppl   227.55\n",
            "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 14.01 | loss  5.47 | ppl   237.24\n",
            "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 13.73 | loss  5.49 | ppl   241.92\n",
            "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 13.72 | loss  5.52 | ppl   249.15\n",
            "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 13.75 | loss  5.46 | ppl   235.44\n",
            "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 14.28 | loss  5.48 | ppl   238.89\n",
            "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 13.78 | loss  5.35 | ppl   210.45\n",
            "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 13.83 | loss  5.46 | ppl   235.12\n",
            "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 13.76 | loss  5.47 | ppl   236.63\n",
            "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 14.13 | loss  5.39 | ppl   219.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 42.59s | valid loss  5.61 | valid ppl   272.95\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataset accuracy"
      ],
      "metadata": {
        "id": "RSSDo_rLwonI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('='*89)\n",
        "print(f'| End of training | test loss {test_loss:5.2f} |'\n",
        "      f'test ppl {test_ppl:8.2f}')\n",
        "print('='*89)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suNeGe0Wvfxa",
        "outputId": "5b2842b9-cd88-415e-f9e5-922540e59c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.51 |test ppl   248.13\n",
            "=========================================================================================\n"
          ]
        }
      ]
    }
  ]
}